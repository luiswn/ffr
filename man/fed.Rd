% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/factor_estimation.R
\name{fed}
\alias{fed}
\title{Eigenvalue difference estimator to determine the number of factors in functional factor regressions}
\usage{
fed(formula, data, gamma = 1, plot = FALSE)
}
\arguments{
\item{formula}{An object of class \code{\link[stats]{formula}} specifying the model. Uses the same
format as in \code{\link{flm}}. A formula specification \code{response ~ .} implies
using all variables in \code{data} except the response.}

\item{data}{A list containing the variables in the model. Each named object within the list is considered
either a functional or a scalar variable, following the same format as in \code{\link{flm}}.}

\item{gamma}{A positive numeric tuning parameter that controls the sensitivity of factor detection.
Default is 1.}

\item{plot}{Logical indicating whether to plot the eigenvalue difference function for visual inspection.
Default is FALSE.}
}
\value{
A list with components:
\item{gamma}{The tuning parameter used}
\item{K}{A named vector containing the estimated number of factors for each functional predictor}
}
\description{
Consistently estimates the correct number of factors for each functional predictor in a function-on-function
regression model using an eigenvalue difference (ED) approach.
}
\details{
The ED estimator for functional factor regressions as introduced by Otto & Winter (2025) determines the number of factors by
finding the largest distance between two subsequent transformed eigenvalues of the integral operator \deqn{D}, which is the
product of the cross-covariance operator between the regressor and the regressand with its adjoint. Consult the original paper
for details about the method.
}
\examples{
\dontrun{
# Simulate functional data

# Define a Fourier basis function
fourier.basis <- function(evalgrid, nbasis) {
  basis <- matrix(NA, length(evalgrid), nbasis)
  for (k in 1:nbasis) {
    if (k == 1) {
      basis[, k] <- rep(1, length(evalgrid))
    } else {
      if (k \%\% 2 == 0) {
        basis[, k] <- sqrt(2) * sin(2 * (k / 2) * pi * evalgrid)
      } else {
        basis[, k] <- sqrt(2) * cos(2 * floor(k / 2) * pi * evalgrid)
      }
    }
  }
  return(basis)
}

# Function to generate random bivariate beta coefficients
rand.biv.beta <- function(Y.grid, X.grid, K, smoothness_penalty = 1, seed) {
  Y.basis <- matrix(NA, length(Y.grid), K)
  X.basis <- matrix(NA, length(X.grid), K)
  for (k in 1:K) {
    if (k == 1) {
      Y.basis[, k] <- rep(1, length(Y.grid))
      X.basis[, k] <- rep(1, length(X.grid))
    } else {
      if (k \%\% 2 == 0) {
        Y.basis[, k] <- sqrt(2) * sin(2 * (k / 2) * pi * Y.grid)
        X.basis[, k] <- sqrt(2) * sin(2 * (k / 2) * pi * X.grid)
      } else {
        Y.basis[, k] <- sqrt(2) * cos(2 * floor(k / 2) * pi * Y.grid)
        X.basis[, k] <- sqrt(2) * cos(2 * floor(k / 2) * pi * X.grid)
      }
    }
  }

  set.seed(seed)

  weights <- exp(-seq(0, 2, length.out = K))

  # Create coefficient matrix with rank K
  A <- matrix(rnorm(K * K), K, K)

  # Ensure coefficient matrix has exactly rank K through SVD
  svd_A <- svd(A)
  A_rank_K <- svd_A$u \%*\% diag(weights) \%*\% t(svd_A$v)

  # Apply smoothness penalty
  A_smooth <- A_rank_K * smoothness_penalty

  biv.func <- Y.basis \%*\% A_smooth \%*\% t(X.basis)

  return(biv.func)
}

# Set up simulation parameters
Y.gridlength <- 200
X.gridlength <- 200
Y.range <- c(0, ((Y.gridlength - 1) / Y.gridlength))
X.range <- c(0, ((X.gridlength - 1) / X.gridlength))
Y.grid <- seq(Y.range[1], Y.range[2], length.out = Y.gridlength)
X.grid <- seq(X.range[1], X.range[2], length.out = X.gridlength)

K <- 3
T <- 100 # Number of observations

# Generate data
four.basis <- fourier.basis(X.grid, 3 * K)

f <- matrix(rnorm(n = T * K, 0, 1), T, K)
z <- cbind(rep(1, nrow(f)), f)
psi <- four.basis[, 1:K]
pred.func <- f \%*\% t(psi)
eps <- matrix(rnorm(n = T * 2 * K, 0, 1), T, 2 * K)
eps.func <- eps \%*\% t(four.basis[, (K + 1):(3 * K)])

# Create functional predictor
X <- pred.func + eps.func

# Generate coefficient surface
beta <- rand.biv.beta(Y.grid, X.grid, K, seed = 1)

intercept <- rep(3, Y.gridlength)

# Generate error term
u <- matrix(rnorm(n = T * 2 * K, 0, 1), T, 2 * K)
u.func <- u \%*\% t(fourier.basis(Y.grid, 2 * K))

# Generate response
Y <- intercept + (X \%*\% beta / X.gridlength) + u.func


# Estimate number of factors
data <- list(Y = Y, X = X)
ED_result <- fed(Y ~ X, data, gamma = 1)
print(ED_result$K) # correct would be K=3
}

}
\references{
Otto, S., & Winter, L. (2025). Functional factor regression with an application to electricity price curve modeling.
Wu, J. (2018). Eigenvalue difference test for the number of common factors in the approximate factor models. Economics Letters, 169, 63â€“67.
}
\seealso{
\code{\link{flm}} for fitting functional linear models, \code{\link{tune.fed}} for tuning the gamma parameter
}
